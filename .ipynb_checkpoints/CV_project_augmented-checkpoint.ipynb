{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN classifier\n",
    "\n",
    "https://cs230.stanford.edu/lecture/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.9.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (58.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.12.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.49.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.23.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install scikit-learn\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "32\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "#BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name() if torch.cuda.is_available() else None)\n",
    "print(BATCH_SIZE)\n",
    "print(NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    '''\n",
    "    Args:\n",
    "    root is the path where are stored the folders.\n",
    "    phase can be 'train' or 'test', in function if\n",
    "    you want a training (Augmented) or test (original) dataset.\n",
    "    batch_size\n",
    "    num_workers\n",
    "    '''\n",
    "    def __init__(self, root_train, root_test, phase, batch_size, num_workers):\n",
    "        self.phase = phase\n",
    "        self.root_train = root_train\n",
    "        self.root_test = root_test\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def apply(self):\n",
    "        transforms_dict = {\n",
    "            'augmented': transforms.Compose([transforms.Resize((64,64)),\n",
    "                                    transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomVerticalFlip()]),\n",
    "            'origin': transforms.Compose([transforms.Resize((64,64)),\n",
    "                                 transforms.Grayscale(num_output_channels=1),\n",
    "                                 transforms.ToTensor()])}\n",
    "\n",
    "        df_augmented = datasets.ImageFolder(root=self.root_train, transform=transforms_dict['augmented'])\n",
    "        df_origin = datasets.ImageFolder(root=self.root_train, transform=transforms_dict['origin'])\n",
    "        df_train, df_val = random_split(df_origin, (round(0.85*len(df_origin)), round(0.15*len(df_origin))))\n",
    "        \n",
    "        df = ConcatDataset([df_train, df_augmented])\n",
    "        print('train', len(df))\n",
    "        print('val', len(df_val))\n",
    "\n",
    "        if self.phase == 'train':\n",
    "    \n",
    "            train_loader = DataLoader(df, batch_size=self.batch_size,\n",
    "                                      shuffle=True, num_workers=self.num_workers)\n",
    "            val_loader = DataLoader(df_val, batch_size=self.batch_size,\n",
    "                                    shuffle=False, num_workers=self.num_workers)\n",
    "            return [train_loader, val_loader]\n",
    "        else:\n",
    "            df_test = datasets.ImageFolder(root=self.root_test, transform=transforms_dict['origin'])\n",
    "            print('test', len(df_test))\n",
    "                                           \n",
    "            test_loader = DataLoader(df_test, batch_size=self.batch_size,\n",
    "                                     shuffle=False, num_workers=self.num_workers)\n",
    "            return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 4016\n",
      "val 326\n",
      "train 4016\n",
      "val 326\n",
      "test 2171\n"
     ]
    }
   ],
   "source": [
    "path_train = 'I:/College/Classifier/class/test'\n",
    "path_test = 'I:/College/Classifier/class/train'\n",
    "load_train = ImageLoader(root_train=path_train, root_test=path_test , phase='train', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "img_train = load_train.apply()\n",
    "\n",
    "load_test = ImageLoader(root_train=path_train, root_test=path_test, phase='test', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "img_test = load_test.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.ImageFolder(root='I:/College/Classifier/class/test', transform=transforms.Compose([transforms.Resize((64,64), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                                                                                                     transforms.Grayscale(num_output_channels=1),\n",
    "                                                                                                        transforms.ToTensor()]))\n",
    "df_test = datasets.ImageFolder(root='I:/College/Classifier/class/train', transform=transforms.Compose([transforms.Resize((64,64), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                                                                                                            transforms.Grayscale(num_output_channels=1),\n",
    "                                                                                                            transforms.ToTensor()]))\n",
    "                                                                                                            \n",
    "dataloader = {\n",
    "    'train': img_train[0],\n",
    "    'val': img_train[1],\n",
    "    'test': img_test\n",
    "}\n",
    "\n",
    "dataset_size = {\n",
    "    'train': 2775,\n",
    "    'val': 255,\n",
    "    'test': 2985\n",
    "}                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(img_train[0])\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    classes = df.classes\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "#     plt.imshow(cv2.cvtColor(img.permute(1, 2, 0), cv2.COLOR_BGR2RGB))\n",
    "    plt.title('label:' + str(classes[label]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(np.random.randint(0, BATCH_SIZE))\n",
    "imshow(images[n], labels[n])\n",
    "images[n].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "  if isinstance(m, nn.Conv2d):\n",
    "      nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "      if m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0)\n",
    "  elif isinstance(m, nn.Linear):\n",
    "      nn.init.kaiming_uniform_(m.weight.data)\n",
    "      nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(1, 8, 3, stride=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(8)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(8, 16, 3, stride=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.cnn3 = nn.Conv2d(16, 32, 3, stride=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(32)\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(4608, 15)\n",
    "        self.fc_bn = nn.BatchNorm1d(15)\n",
    "        self.dropfc = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = self.conv3_bn(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc_bn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (cnn1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (cnn2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (cnn3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop3): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=4608, out_features=15, bias=True)\n",
       "  (fc_bn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropfc): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.apply(initialize_weights)\n",
    "#model.to(device)\n",
    "#model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "diFSQMBz8mDV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2oF-6zamYBBc"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=201):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader[phase]:\n",
    "                #inputs = inputs.to(device)\n",
    "                #labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "          \n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "\n",
    "            writer.add_scalar(f\"Loss {phase}\", epoch_loss, epoch)\n",
    "            writer.add_scalar(f\"Acc {phase}\", epoch_acc, epoch)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 235, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 230, in __getitem__\n    sample = self.loader(path)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 248, in pil_loader\n    img = Image.open(f)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py\", line 3147, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='I:/College/Classifier/class/test\\\\docs\\\\5.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m writer\u001b[38;5;241m.\u001b[39mflush()\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloader[phase]:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#inputs = inputs.to(device)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#labels = labels.to(device)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# track history if only in train\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1402\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 235, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 290, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 230, in __getitem__\n    sample = self.loader(path)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 248, in pil_loader\n    img = Image.open(f)\n  File \"C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py\", line 3147, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='I:/College/Classifier/class/test\\\\docs\\\\5.jpg'>\n"
     ]
    }
   ],
   "source": [
    "Model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=201)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model.state_dict(), 'I:/College/Classifier/augumented/model_dict_augmented.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.close()\n",
    "# import tensorboard\n",
    "# %load_ext tensorboard\n",
    "# !kill 6204\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=runs\n",
    "\n",
    "writer.close()\n",
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "def get_predict(model, loader):\n",
    "    predict_tensor = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        predict = model(images)\n",
    "        # _, preds = torch.max(predict, 1)\n",
    "        \n",
    "        predict_tensor = torch.cat(\n",
    "            (predict_tensor, predict),\n",
    "            dim=0)\n",
    "\n",
    "    return predict_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_predict = get_predict(Model, img_test)\n",
    "    \n",
    "test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_predict.requires_grad)\n",
    "print(test_predict.grad)\n",
    "print(test_predict.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "predict_correct = get_num_correct(test_predict, torch.tensor(df_test.targets))\n",
    "\n",
    "print(predict_correct)\n",
    "print(predict_correct/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack(\n",
    "    (torch.tensor(df_test.targets),\n",
    "    #test_predict.int()),\n",
    "    test_predict.argmax(dim=1)),\n",
    "    dim=1\n",
    ")\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt = torch.zeros(15,15, dtype=torch.int32)\n",
    "for p in stacked:\n",
    "    i,j = p.tolist()\n",
    "    cmt[i,j] = cmt[i,j] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(torch.tensor(df_test.targets), test_predict.argmax(dim=1))\n",
    "\n",
    "names = df_test.classes\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_confusion_matrix(cm, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "#     plt.imshow(cv2.cvtColor(inp, cv2.COLOR_BGR2RGB))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "\n",
    "def visualize_model(model, num_images=10):\n",
    "    model.load_state_dict(torch.load(\"I:/College/Classifier/augumented/model_dict_augmented.pt\"))\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader['test']):\n",
    "            #inputs = inputs.to(device)\n",
    "            #labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {df.classes[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax classifier\n",
    "\n",
    "class SoftMax(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ca6fba6cd343157984bf9ab78c17ea43484b522abbae068c469a0354c66129a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
